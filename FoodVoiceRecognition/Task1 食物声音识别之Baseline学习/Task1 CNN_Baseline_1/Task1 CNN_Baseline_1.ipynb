{"cells":[{"metadata":{"_uuid":"edef0863-5069-491e-b432-923fb4a5e708","_cell_guid":"2d1d020f-ae41-46a2-9060-aeb1ab73433c","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e411f75-3649-4e2d-8668-aab192ba0cda","_cell_guid":"1690a355-e15b-4412-9fa2-dc7eb11678a3","trusted":true},"cell_type":"markdown","source":"## 版本提示\nTensorFlow的版本：2.4.0"},{"metadata":{"_uuid":"0af303d3-a2e4-4fe1-88c4-8cd07e7b817f","_cell_guid":"8e73baeb-4378-43f3-8e9f-9e964dd5057c","trusted":true},"cell_type":"code","source":"# 基本库\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b928ad54-4d82-4828-bce3-b05fc1fa39b4","_cell_guid":"b9a900b7-0770-47d2-bb01-99b510d22b66","trusted":true},"cell_type":"markdown","source":"# 加载深度学习框架"},{"metadata":{"_uuid":"ff7ff39c-eae9-4f3a-a843-363213d18ab7","_cell_guid":"5b4d74d3-1044-45bd-a7a5-5171fcd91f9b","trusted":true},"cell_type":"code","source":"# 搭建分类模型所需要的库\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\nfrom tensorflow.keras.utils import to_categorical \n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c88fb9e-9494-418d-a7d8-d66d9fe33d87","_cell_guid":"942d529c-908c-45cc-be3c-fdb43aa9a5ed","trusted":true},"cell_type":"markdown","source":"# 加载音频处理库"},{"metadata":{"_uuid":"d9c93921-94f8-4deb-b617-f2b51121b78a","_cell_guid":"b7be5ed1-203e-41a5-ad92-7135b05e04d6","trusted":true},"cell_type":"code","source":"# 其他库\n\nimport os\nimport librosa\nimport librosa.display\nimport glob \nimport skimage","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a95ca65-20de-4605-b973-4c06421cc435","_cell_guid":"4c38c5c7-4f06-49b3-bdb4-21137a570208","trusted":true},"cell_type":"markdown","source":"## 特征提取以及数据集的建立"},{"metadata":{"_uuid":"d0f07329-8f48-4bc9-854b-a3fc7bf1d3f0","_cell_guid":"6b206263-0653-4739-91a2-658a834194eb","trusted":true},"cell_type":"code","source":"feature = []\nlabel = []\n# 建立类别标签，不同类别对应不同的数字。\nlabel_dict = {'aloe': 0, 'burger': 1, 'cabbage': 2,'candied':3, 'carrots': 4, 'chips':5,\n                  'chocolate': 6, 'drinks': 7, 'fries': 8, 'grapes': 9, 'gummies': 10, 'ice-cream':11,\n                  'jelly': 12, 'noodles': 13, 'pickles': 14, 'pizza': 15, 'ribs': 16, 'salmon':17,\n                  'soup': 18, 'wings': 19}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9d82d53-378f-432c-92da-e068627e6246","_cell_guid":"ff434b85-f25e-49a0-8326-2594056571ce","trusted":true},"cell_type":"markdown","source":"建立提取音频特征的函数"},{"metadata":{"_uuid":"217a7126-f097-43d4-886c-f3ee816136ff","_cell_guid":"f3ab0d81-d981-4e10-aba4-9f1f42f8fd4c","trusted":true},"cell_type":"code","source":"def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n    for sub_dir in sub_dirs:\n        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)): # 遍历数据集的所有文件\n            \n           # segment_log_specgrams, segment_labels = [], []\n            #sound_clip,sr = librosa.load(fn)\n            #print(fn)\n            label_name = fn.split('/')[5].split('_')[0]   \n            label.extend([label_dict[label_name]])\n            X, sample_rate = librosa.load(fn,res_type='kaiser_fast')\n            mels = np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0) # 计算梅尔频谱(mel spectrogram),并把它作为特征\n            feature.extend([mels])\n    return [feature, label]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a582ebd-5a47-4de7-9cfb-cd965c67d2eb","_cell_guid":"e07a5a98-7629-459e-995b-94d1334e667d","trusted":true},"cell_type":"code","source":"# 自己更改目录\nparent_dir = '../input/eating-sound-collection/clips_rd'\nsave_dir = \"./\"\nfolds = sub_dirs = np.array(['aloe','burger','cabbage','candied_fruits',\n                             'carrots','chips','chocolate','drinks','fries',\n                            'grapes','gummies','ice-cream','jelly','noodles','pickles',\n                            'pizza','ribs','salmon','soup','wings'])\n\n# 获取特征feature以及类别的label\ntemp = extract_features(parent_dir,sub_dirs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0f2e227-c66a-4f0b-afe4-8eb3c916a71a","_cell_guid":"f29f3f21-a7b8-49fa-8a0a-47742c416321","trusted":true},"cell_type":"code","source":"temp = np.array(temp)\ndata = temp.transpose()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75bd2b8f-a826-4fbc-bd2e-b15c0a25e52e","_cell_guid":"106a721d-097e-4d46-bf69-29f6fb9283c0","trusted":true},"cell_type":"code","source":"# 获取特征\n#X_ = data[:,0]\nX_ = data[:,0]\n# 获取标签\nY = data[:, 1]\nprint('X的特征尺寸是：',X_.shape)\nprint('Y的特征尺寸是：',Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f191e2a-6aa9-4272-860a-b53303ed7960","_cell_guid":"6cb8bd1d-ecf2-4a55-8642-1b018c5b8627","trusted":true},"cell_type":"code","source":"X = np.empty([11140, 128])\nfor i in range(11140):\n    X[i] = (X_[i])\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa0a6189-0d26-4652-ba45-f09af29ffde7","_cell_guid":"113ee21c-f1c7-40e3-84fb-e67dd7e70a1e","trusted":true},"cell_type":"code","source":"# 在Keras库中：to_categorical就是将类别向量转换为二进制（只有0和1）的矩阵类型表示\nY = to_categorical(Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"657de60d-7dbc-40aa-9c4a-8bbbbdf48441","_cell_guid":"ef030784-e3d3-4f40-ba05-226ce429ec3a","trusted":true},"cell_type":"code","source":"'''最终数据'''\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2e8aa6d-ed3d-44da-9c07-6f018f673048","_cell_guid":"8f01e65f-1d69-42bc-a129-685b940f0c42","trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\nprint('训练集的大小',len(X_train))\nprint('测试集的大小',len(X_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6593560-df5e-4f54-a2d9-095653bc322f","_cell_guid":"dd16ee67-0ff2-47da-bce1-c0fcd3acce66","trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(8355, 16, 8, 1)\nX_test = X_test.reshape(2785, 16, 8, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b1814a7-a264-4820-968a-fa8fac82c92d","_cell_guid":"e48bc026-cc99-4922-9e21-7c17b367d694","trusted":true},"cell_type":"markdown","source":"## 建立模型"},{"metadata":{"_uuid":"3d43e750-8b5f-4adf-bb3d-08c7da224317","_cell_guid":"c3f8fc53-fc70-40ed-8c72-562833bd6089","trusted":true},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"207c68bc-cca4-4d43-932e-679cd1dec2cf","_cell_guid":"72ef3484-25bc-48a2-b9ff-53a2170b11f2","trusted":true},"cell_type":"markdown","source":"### 搭建CNN网络"},{"metadata":{"_uuid":"0cad033c-1427-4df4-9d3d-0e3533c06213","_cell_guid":"0b7f4483-8197-4ad4-b55c-8ad8964d1942","trusted":true},"cell_type":"code","source":"# 输入的大小\ninput_dim = (16, 8, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52d35a19-c90f-4d64-9718-a11f3d1e59f6","_cell_guid":"9fb3daa1-c6a9-4868-8f92-24de67d2fb00","trusted":true},"cell_type":"code","source":"model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))# 卷积层\nmodel.add(MaxPool2D(pool_size=(2, 2)))# 最大池化\nmodel.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\")) #卷积层\nmodel.add(MaxPool2D(pool_size=(2, 2))) # 最大池化层\nmodel.add(Dropout(0.1))\nmodel.add(Flatten()) # 展开\nmodel.add(Dense(1024, activation = \"tanh\"))\nmodel.add(Dense(20, activation = \"softmax\")) # 输出层：20个units输出20个类的概率","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c72012c-74fc-416c-8f6d-e079a66ebb60","_cell_guid":"00c3ed65-3c70-442f-b5a4-976b3c2ae349","trusted":true},"cell_type":"code","source":"# 编译模型，设置损失函数，优化方法以及评价标准\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f490ef6-ac8f-4906-8f0f-2d34187603e9","_cell_guid":"77c4a280-6ba7-42c4-b682-bc0650ed72d4","trusted":true},"cell_type":"markdown","source":"### CNN模型的的训练"},{"metadata":{"_uuid":"ed466b8b-ceed-440d-93c1-f2dd1e4fdef1","_cell_guid":"f291395b-53d9-4d62-b2a7-8684867d4884","trusted":true},"cell_type":"code","source":"# 训练模型\nmodel.fit(X_train, Y_train, epochs = 90, batch_size = 50, validation_data = (X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbc50bbc-7f81-447d-87fa-9c412401b7cf","_cell_guid":"0c7ad547-1f66-4432-a176-80a8877131a3","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c846727b-eb89-4fe6-8b65-987221ea51e9","_cell_guid":"c292ae0b-5af4-47ea-9817-7d829783f222","trusted":true},"cell_type":"markdown","source":"### 预测测试集"},{"metadata":{},"cell_type":"markdown","source":"新的数据生成预测"},{"metadata":{"_uuid":"3fc08666-6dc9-4a99-9921-8776001c1b29","_cell_guid":"9af0a34d-5d47-4b31-bc6d-a10d17ec887e","trusted":true},"cell_type":"code","source":"# 模型预测\npredictions = model.predict(X_test)\nscore = model.evaluate(X_test, Y_test)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f25c6a16-de6f-4dfb-a51b-b927d5cf5b99","_cell_guid":"ba021f6a-ba3a-406e-b7c4-2487bd4f3d37","trusted":true},"cell_type":"code","source":"preds = np.argmax(predictions, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92a49f0e-f398-411a-abd3-f3dfb0c37a70","_cell_guid":"5582017f-4d04-48e9-9cff-f5f014cb8183","trusted":true},"cell_type":"code","source":"result = pd.DataFrame(preds)\nresult.to_csv(\"food_rc.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"394a5ee0-aac6-4833-aa62-34412ad60e68","_cell_guid":"4b635729-dc55-4638-87d9-3b79614648d5","trusted":true},"cell_type":"code","source":"result = pd.read_csv('./food_rc.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c606bc9-dde5-4d50-a912-59dbcc842e31","_cell_guid":"257809b1-d24c-4e60-b336-00ea461dc8d2","trusted":true},"cell_type":"code","source":"result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}